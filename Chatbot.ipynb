{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import time\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "ISTXT = 1\n",
    "ISPDF = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to open file dialog and get selected files\n",
    "def get_file_paths():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    # Set initial directory to \"Output text\"\n",
    "    initial_dir = \"Output text\"\n",
    "    \n",
    "    file_paths = filedialog.askopenfilenames(\n",
    "        title=\"Select Files\",\n",
    "        filetypes=[(\"Text files\", \"*.txt\"), (\"PDF files\", \"*.pdf\")],\n",
    "        initialdir=initial_dir,\n",
    "    )\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files inside 'Output text' folder:\n",
      "2024-01-31 15:56:35.001407.txt\n",
      ".DS_Store\n",
      "2024-02-02 13:10:41.305387.txt\n",
      "Camera Enhanced Real-Time Content-Aware Vehicle Detection..pdf\n"
     ]
    }
   ],
   "source": [
    "# Get file paths from the user\n",
    "file_paths = get_file_paths()\n",
    "\n",
    "# List files in the \"Output text\" folder\n",
    "output_text_files = os.listdir(\"Output text\")\n",
    "print(\"Files inside 'Output text' folder:\")\n",
    "for file in output_text_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read text from selected files\n",
    "raw_text = \"\"\n",
    "for file_path in file_paths:\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        pdf_reader = PdfReader(file_path)\n",
    "        for i, page in enumerate(pdf_reader.pages):\n",
    "            content = page.extract_text()\n",
    "            if content:\n",
    "                raw_text += content\n",
    "    elif file_path.endswith(\".txt\"):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            raw_text += f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1434, which is longer than the specified 1000\n",
      "Created a chunk of size 1756, which is longer than the specified 1000\n",
      "Created a chunk of size 1769, which is longer than the specified 1000\n",
      "Created a chunk of size 1600, which is longer than the specified 1000\n",
      "Created a chunk of size 1434, which is longer than the specified 1000\n",
      "Created a chunk of size 1756, which is longer than the specified 1000\n",
      "Created a chunk of size 2696, which is longer than the specified 1000\n",
      "Created a chunk of size 1172, which is longer than the specified 1000\n",
      "Created a chunk of size 3089, which is longer than the specified 1000\n",
      "Created a chunk of size 1315, which is longer than the specified 1000\n",
      "Created a chunk of size 1042, which is longer than the specified 1000\n",
      "Created a chunk of size 1553, which is longer than the specified 1000\n",
      "Created a chunk of size 5465, which is longer than the specified 1000\n",
      "Created a chunk of size 1314, which is longer than the specified 1000\n",
      "Created a chunk of size 1128, which is longer than the specified 1000\n",
      "Created a chunk of size 1596, which is longer than the specified 1000\n",
      "Created a chunk of size 2352, which is longer than the specified 1000\n",
      "Created a chunk of size 3458, which is longer than the specified 1000\n",
      "Created a chunk of size 4742, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "# Split text using Character Text Split\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\", chunk_size=1000, chunk_overlap=600, length_function=len\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download embeddings from OpenAI\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Create FAISS vector store from texts\n",
    "document_search = FAISS.from_texts(texts, embeddings)\n",
    "\n",
    "# Load question-answering chain\n",
    "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, the lookup table is being used to find the location of objects in the image. The function 'get_Dis_Loc' utilizes the lookup table to determine the objects in the vicinity that match the expected distance. The choice of data points is based on the object's position, specifically, whether it lies to the left or right of the image centre. The lookup table is consulted to determine the objects in the vicinity that match the expected distance. The data point with the minimum combined difference is selected as the most likely prediction for the object's location. This prediction is represented by the 'LocX' and 'LocY' coordinates.\n"
     ]
    }
   ],
   "source": [
    "# Query for user\n",
    "query = \"how is location being foud out?, is lookup table being used?\"\n",
    "\n",
    "# Similarity search and question answering\n",
    "docs = document_search.similarity_search(query)\n",
    "ans = chain.run(input_documents=docs, question=query)\n",
    "\n",
    "# Display the result\n",
    "print(ans)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
